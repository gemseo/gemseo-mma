{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#gemseo-mma","title":"gemseo-mma","text":""},{"location":"#overview","title":"Overview","text":"<p>A gemseo wrapper of Python version of Method of Moving Asymptothes in the implementation of Arjen Deetman.</p>"},{"location":"#installation","title":"Installation","text":"<p>Install the latest version with <code>pip install gemseo-mma</code>.</p> <p>See pip for more information.</p>"},{"location":"#bugs-and-questions","title":"Bugs and questions","text":"<p>Please use the gitlab issue tracker to submit bugs or questions.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>See the contributing section of GEMSEO.</p>"},{"location":"#contributors","title":"Contributors","text":"<ul> <li>Simone Coniglio</li> <li>Antoine Dechaume</li> <li>Original implementation of Arjen Deetman, see here.</li> </ul>"},{"location":"#references","title":"References","text":"<p>Svanberg, K. (1987). The Method of Moving Asymptotes -- A new method for structural optimization. International Journal for Numerical Methods in Engineering 24, 359-373. <code>doi:10.1002/nme.1620240207</code>, see here.</p> <p>Svanberg, K. (n.d.). MMA and GCMMA -- two methods for nonlinear optimization. Retrieved August 3, 2017 from this.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":"<p>All notable changes of this project will be documented here.</p> <p>The format is based on Keep a Changelog and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>The <code>MMASvanbergSettings</code> class was moved to <code>gemseo_mma.opt.settings.mma_settings</code> and renamed   to <code>MMASvanberg_Settings</code> in order to follow GEMSEO conventions.</li> </ul>"},{"location":"changelog/#version-300-november-2024","title":"Version 3.0.0 (November 2024)","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Support GEMSEO v6.</li> <li>Support for Python 3.12.</li> </ul>"},{"location":"changelog/#version-202-august-2024","title":"Version 2.0.2 (August 2024)","text":""},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>The license of the package is now GPLv3 since it uses a module that is GPLv3.</li> </ul>"},{"location":"changelog/#version-201-december-2023","title":"Version 2.0.1 (December 2023)","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Support for Python 3.11.</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>A bug on the option handling was solved for design space normalization   and inequality constraint tolerance.</li> </ul>"},{"location":"changelog/#removed","title":"Removed","text":"<ul> <li>Support for Python 3.8.</li> </ul>"},{"location":"changelog/#version-200-june-2023","title":"Version 2.0.0 (June 2023)","text":"<p>Update to GEMSEO 5.</p>"},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li>A bug on the option settings was solved.</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>The <code>ctol_abs</code> option was removed, this was anyway not used.</li> <li>The attributes and option names were changed to be more explicit.</li> <li>The solver attributes are made private.</li> </ul>"},{"location":"changelog/#version-100-february-2023","title":"Version 1.0.0 (February 2023)","text":"<p>First release.</p>"},{"location":"credits/","title":"Credits","text":""},{"location":"credits/#exec-1--credits","title":"Credits","text":"<p>These projects were used to build gemseo-mma. Thank you!</p> <p>Python | uv</p>"},{"location":"credits/#exec-1--runtime-dependencies","title":"Runtime dependencies","text":"Project Summary Version (accepted) Version (last resolved) License annotated-types Reusable constraint types to use with typing.Annotated <code>&gt;=0.6.0</code> <code>0.7.0</code> MIT License certifi Python package for providing Mozilla's CA Bundle. <code>&gt;=2017.4.17</code> <code>2025.10.5</code> MPL-2.0 charset-normalizer The Real First Universal Charset Detector. Open, modern and actively maintained alternative to Chardet. <code>&gt;=2, &lt;4</code> <code>3.4.3</code> MIT colorama Cross-platform colored terminal text. <code>&gt;=0.4</code> <code>0.4.6</code> BSD License contourpy Python library for calculating contours of 2D quadrilateral grids <code>&gt;=1.0.1</code> <code>1.3.3</code> BSD License cycler Composable style cycles <code>&gt;=0.10</code> <code>0.12.1</code> BSD License dill serialize all of Python <code>0.4.0</code> BSD-3-Clause docstring-inheritance Avoid writing and maintaining duplicated docstrings. <code>&gt;=2.0.0, &lt;=2.2.2</code> <code>2.2.2</code> MIT et_xmlfile An implementation of lxml.xmlfile for the standard library <code>2.0.0</code> MIT fastjsonschema Fastest Python implementation of JSON schema <code>&gt;=2.14.5, &lt;=2.21.2</code> <code>2.21.2</code> BSD fonttools Tools to manipulate font files <code>&gt;=4.22.0</code> <code>4.60.1</code> MIT gemseo Generic Engine for Multi-disciplinary Scenarios, Exploration and Optimization <code>&gt;=6, &lt;7</code> <code>6.2.1.dev458+g6fe827a0d</code> LGPL-3.0 genson GenSON is a powerful, user-friendly JSON Schema generator. <code>&gt;=1.2.2, &lt;=1.3.0</code> <code>1.3.0</code> MIT graphviz Simple Python interface for Graphviz <code>&gt;=0.19, &lt;=0.21</code> <code>0.21</code> MIT h5py Read and write HDF5 files from Python <code>&gt;=3.6.0, &lt;=3.14.0</code> <code>3.14.0</code> BSD-3-Clause idna Internationalized Domain Names in Applications (IDNA) <code>&gt;=2.5, &lt;4</code> <code>3.10</code> BSD License Jinja2 A very fast and expressive template engine. <code>&gt;=3.0.0, &gt;=2.11.1, &lt;=3.1.6</code> <code>3.1.6</code> BSD License joblib Lightweight pipelining with Python functions <code>&gt;=1.2.0</code> <code>1.5.2</code> BSD 3-Clause kiwisolver A fast implementation of the Cassowary constraint solver <code>&gt;=1.3.1</code> <code>1.4.9</code> BSD License MarkupSafe Safely add untrusted strings to HTML/XML markup. <code>&gt;=2.0, &gt;=1.1</code> <code>3.0.3</code> BSD-3-Clause matplotlib Python plotting package <code>&gt;=3.6.0, &lt;=3.10.6</code> <code>3.10.6</code> Python Software Foundation License MiniSom Minimalistic implementation of the Self Organizing Maps (SOM) <code>&gt;=2.3.5, &lt;2.4</code> <code>2.3.5</code> MIT mpmath Python library for arbitrary-precision floating-point arithmetic <code>&gt;=1.1.0, &lt;1.4</code> <code>1.3.0</code> BSD narwhals Extremely lightweight compatibility layer between dataframe libraries <code>&gt;=1.15.1</code> <code>2.7.0</code> MIT License networkx Python package for creating and manipulating graphs and networks <code>&gt;=2.5, &lt;=3.5</code> <code>3.5</code> BSD License nlopt Library for nonlinear optimization, wrapping many algorithms for global and local, constrained or unconstrained, optimization <code>&gt;=2.7.0, &lt;=2.9.1</code> <code>2.9.1</code> MIT numpy Fundamental package for array computing in Python <code>2.3.3</code> BSD License openpyxl A Python library to read/write Excel 2010 xlsx/xlsm files <code>&gt;=3.0.10, &lt;=3.1.5</code> <code>3.1.5</code> MIT openturns Uncertainty treatment library <code>&gt;=1.20, &lt;=1.25</code> <code>1.25</code> LGPL packaging Core utilities for Python packages <code>&gt;=20.5, &gt;=15, &lt;=25</code> <code>25.0</code> Apache Software License + BSD License pandas Powerful data structures for data analysis, time series, and statistics <code>&gt;=2.1.0, &lt;=2.3.2</code> <code>2.3.2</code> BSD License pillow Python Imaging Library (Fork) <code>&gt;=9.5.0, &lt;=11.3.0</code> <code>11.3.0</code> MIT-CMU plotly An open-source interactive data visualization library for Python <code>&gt;=5.7.0, &lt;=6.3.0</code> <code>6.3.0</code> MIT License prettytable A simple Python library for easily displaying tabular data in a visually appealing ASCII table format <code>&gt;=2.3.0, &lt;=3.16.0</code> <code>3.16.0</code> BSD-3-Clause psutil Cross-platform lib for process and system monitoring. <code>7.1.0</code> BSD-3-Clause pydantic Data validation using Python type hints <code>&gt;=2.7, &lt;=2.11.9</code> <code>2.11.9</code> MIT pydantic-settings Settings management using Pydantic <code>&gt;=2.1.0, &lt;=2.11.0</code> <code>2.11.0</code> MIT pydantic_core Core functionality for Pydantic validation and serialization <code>==2.33.2</code> <code>2.33.2</code> MIT pyDOE3 Design of experiments for Python <code>&gt;=1.0.1, &lt;=1.4.0</code> <code>1.4.0</code> BSD-3-Clause pyparsing pyparsing - Classes and methods to define and execute parsing grammars <code>&gt;=3.0, &gt;=2.3.1</code> <code>3.2.5</code> MIT python-dateutil Extensions to the standard Python datetime module <code>&gt;=2.8.2, &gt;=2.8.1</code> <code>2.9.0.post0</code> BSD License + Apache Software License python-dotenv Read key-value pairs from a .env file and set them as environment variables <code>&gt;=0.21.0</code> <code>1.1.1</code> BSD-3-Clause pytz World timezone definitions, modern and historical <code>&gt;=2020.1, &gt;=2015.7</code> <code>2025.2</code> MIT pyXDSM Python script to generate PDF XDSM diagrams using TikZ and LaTeX <code>&gt;=2.2.1, &lt;=2.3.1</code> <code>2.3.1</code> Apache License Version 2.0 requests Python HTTP for Humans. <code>&gt;=2.8.1, &gt;2, &lt;3</code> <code>2.32.5</code> Apache-2.0 scikit-learn A set of python modules for machine learning and data mining <code>&gt;=1.2, &lt;=1.7.2</code> <code>1.7.2</code> BSD-3-Clause scipy Fundamental algorithms for scientific computing in Python <code>1.15.2</code> BSD License six Python 2 and 3 compatibility utilities <code>&gt;=1.5</code> <code>1.17.0</code> MIT spgl1 SPGL1: A solver for large-scale sparse reconstruction. <code>&gt;=0.0.3, &lt;=1.0.0</code> <code>0.0.3</code> GNU Lesser General Public License v3 (LGPLv3) StrEnum An Enum that inherits from str. <code>&gt;=0.4.9, &lt;=0.4.15</code> <code>0.4.15</code> MIT License sympy Computer algebra system (CAS) in Python <code>&gt;=1.5, &lt;=1.14.0</code> <code>1.14.0</code> BSD threadpoolctl threadpoolctl <code>&gt;=3.1.0</code> <code>3.6.0</code> BSD-3-Clause tqdm Fast, Extensible Progress Meter <code>&gt;=4.50, &lt;=4.67.1</code> <code>4.67.1</code> MPL-2.0 AND MIT typing-inspection Runtime typing introspection tools <code>&gt;=0.4.0</code> <code>0.4.2</code> MIT typing_extensions Backported and Experimental Type Hints for Python 3.9+ <code>&gt;=4.0, &gt;=4, &lt;5</code> <code>4.15.0</code> PSF-2.0 tzdata Provider of IANA time zone data <code>&gt;=2022.7</code> <code>2025.2</code> Apache-2.0 urllib3 HTTP library with thread-safe connection pooling, file post, and more. <code>&gt;=1.21.1, &lt;3</code> <code>2.5.0</code> MIT wcwidth Measures the displayed width of unicode strings in a terminal <code>0.2.14</code> MIT xdsmjs XDSMjs Python module <code>&gt;=1.0.0, &lt;=2.0.0</code> <code>2.0.0</code> Apache License, Version 2.0 xxhash Python binding for xxHash <code>&gt;=3.0.0, &lt;=3.5.0</code> <code>3.5.0</code> BSD"},{"location":"credits/#exec-1--development-dependencies","title":"Development dependencies","text":"Project Summary Version (accepted) Version (last resolved) License babel Internationalization utilities <code>~=2.10</code> <code>2.17.0</code> BSD-3-Clause backrefs A wrapper around re and regex that adds additional back references. <code>~=5.7.post1</code> <code>5.9</code> MIT black The uncompromising code formatter. <code>25.9.0</code> MIT bracex Bash style brace expander. <code>&gt;=2.1.1</code> <code>2.6</code> MIT certifi Python package for providing Mozilla's CA Bundle. <code>&gt;=2017.4.17</code> <code>2025.10.5</code> MPL-2.0 charset-normalizer The Real First Universal Charset Detector. Open, modern and actively maintained alternative to Chardet. <code>&gt;=2, &lt;4</code> <code>3.4.3</code> MIT click Composable command line interface toolkit <code>&gt;=7.0</code> <code>8.3.0</code> BSD-3-Clause colorama Cross-platform colored terminal text. <code>&gt;=0.4</code> <code>0.4.6</code> BSD License fieldz Utilities for providing compatibility with many dataclass-like libraries <code>&gt;=0.1.0</code> <code>0.1.3</code> BSD-3-Clause ghp-import Copy your docs directly to the gh-pages branch. <code>&gt;=1.0</code> <code>2.1.0</code> Apache Software License griffe Signatures for entire Python programs. Extract the structure, the frame, the skeleton of your project, to generate API documentation or find breaking changes in your API. <code>&gt;=1.13</code> <code>1.14.0</code> ISC griffe-fieldz Griffe extension adding support for data-class like things (pydantic, attrs, etc...) <code>0.3.0</code> BSD-3-Clause griffe-inherited-docstrings Griffe extension for inheriting docstrings. <code>1.1.2</code> ISC idna Internationalized Domain Names in Applications (IDNA) <code>&gt;=2.5, &lt;4</code> <code>3.10</code> BSD License importlib_metadata Read metadata from Python packages <code>&gt;=4.6</code> <code>8.7.0</code> Apache Software License importlib_resources Read resources from Python packages <code>6.5.2</code> Apache Software License Jinja2 A very fast and expressive template engine. <code>&gt;=3.0.0, &gt;=2.11.1, &lt;=3.1.6</code> <code>3.1.6</code> BSD License latexcodec A lexer and codec to work with LaTeX code in Python. <code>&gt;=1.0.4</code> <code>3.0.1</code> MIT Markdown Python implementation of John Gruber's Markdown. <code>&gt;=3.6</code> <code>3.9</code> BSD-3-Clause markdown-exec Utilities to execute code blocks in Markdown files. <code>1.11.0</code> ISC MarkupSafe Safely add untrusted strings to HTML/XML markup. <code>&gt;=2.0, &gt;=1.1</code> <code>3.0.3</code> BSD-3-Clause mergedeep A deep merge function for \ud83d\udc0d. <code>&gt;=1.3.4</code> <code>1.3.4</code> MIT License mike Manage multiple versions of your MkDocs-powered documentation <code>2.1.3</code> BSD-3-Clause mkdocs Project documentation with Markdown. <code>&gt;=1.2</code> <code>1.6.1</code> BSD-2-Clause mkdocs-autorefs Automatically link across pages in MkDocs. <code>&gt;=1.4</code> <code>1.4.3</code> ISC mkdocs-bibtex An MkDocs plugin that enables managing citations with BibTex <code>4.4.0</code> BSD-3-Clause-LBNL mkdocs-gallery a <code>mkdocs</code> plugin to generate example galleries from python scripts, similar to <code>sphinx-gallery</code>. <code>0.10.4</code> BSD 3-Clause mkdocs-gen-files MkDocs plugin to programmatically generate documentation pages during the build <code>0.5.0</code> MIT mkdocs-get-deps MkDocs extension that lists all dependencies according to a mkdocs.yml file <code>&gt;=0.2.0</code> <code>0.2.0</code> MIT mkdocs-include-markdown-plugin Mkdocs Markdown includer plugin. <code>7.2.0</code> Apache-2.0 mkdocs-literate-nav MkDocs plugin to specify the navigation in Markdown instead of YAML <code>0.6.2</code> MIT mkdocs-material Documentation that simply works <code>9.6.21</code> MIT mkdocs-material-extensions Extension pack for Python Markdown and MkDocs Material. <code>~=1.3</code> <code>1.3.1</code> MIT mkdocs-section-index MkDocs plugin to allow clickable sections that lead to an index page <code>0.3.10</code> MIT mkdocstrings Automatic documentation from sources, for MkDocs. <code>0.30.1</code> ISC mkdocstrings-python A Python handler for mkdocstrings. <code>&gt;=1.16.2</code> <code>1.18.2</code> ISC mypy_extensions Type system extensions for programs checked with the mypy type checker. <code>&gt;=0.4.3</code> <code>1.1.0</code> MIT packaging Core utilities for Python packages <code>&gt;=20.5, &gt;=15, &lt;=25</code> <code>25.0</code> Apache Software License + BSD License paginate Divides large result sets into pages for easier browsing <code>~=0.5</code> <code>0.5.7</code> MIT pathspec Utility library for gitignore style pattern matching of file paths. <code>&gt;=0.11.1</code> <code>0.12.1</code> Mozilla Public License 2.0 (MPL 2.0) platformdirs A small Python package for determining appropriate platform-specific dirs, e.g. a <code>user data dir</code>. <code>&gt;=2.2.0</code> <code>4.4.0</code> MIT pybtex A BibTeX-compatible bibliography processor in Python <code>&gt;=0.22</code> <code>0.25.1</code> MIT Pygments Pygments is a syntax highlighting package written in Python. <code>~=2.16</code> <code>2.19.2</code> BSD-2-Clause pygments-ansi-color <code>&gt;=0.3</code> <code>0.3.0</code> Apache Software License pymdown-extensions Extension pack for Python Markdown. <code>&gt;=6.3</code> <code>10.16.1</code> MIT pypandoc Thin wrapper for pandoc. <code>&gt;=1.5</code> <code>1.15</code> MIT pyparsing pyparsing - Classes and methods to define and execute parsing grammars <code>&gt;=3.0, &gt;=2.3.1</code> <code>3.2.5</code> MIT python-dateutil Extensions to the standard Python datetime module <code>&gt;=2.8.2, &gt;=2.8.1</code> <code>2.9.0.post0</code> BSD License + Apache Software License pytokens A Fast, spec compliant Python 3.12+ tokenizer that runs on older Pythons. <code>&gt;=0.1.10</code> <code>0.1.10</code> MIT pytz World timezone definitions, modern and historical <code>&gt;=2020.1, &gt;=2015.7</code> <code>2025.2</code> MIT PyYAML YAML parser and emitter for Python <code>&gt;=5.1</code> <code>6.0.3</code> MIT pyyaml_env_tag A custom YAML tag for referencing environment variables in YAML files. <code>&gt;=0.1</code> <code>1.1</code> MIT requests Python HTTP for Humans. <code>&gt;=2.8.1, &gt;2, &lt;3</code> <code>2.32.5</code> Apache-2.0 responses A utility library for mocking out the <code>requests</code> Python library. <code>&gt;=0.25.6</code> <code>0.25.8</code> Apache 2.0 setuptools Easily download, build, install, upgrade, and uninstall Python packages <code>&gt;=68.0.0</code> <code>80.9.0</code> MIT six Python 2 and 3 compatibility utilities <code>&gt;=1.5</code> <code>1.17.0</code> MIT tqdm Fast, Extensible Progress Meter <code>&gt;=4.50, &lt;=4.67.1</code> <code>4.67.1</code> MPL-2.0 AND MIT typing_extensions Backported and Experimental Type Hints for Python 3.9+ <code>&gt;=4.0, &gt;=4, &lt;5</code> <code>4.15.0</code> PSF-2.0 urllib3 HTTP library with thread-safe connection pooling, file post, and more. <code>&gt;=1.21.1, &lt;3</code> <code>2.5.0</code> MIT validators Python Data Validation for Humans\u2122 <code>&gt;=0.19.0</code> <code>0.35.0</code> MIT verspec Flexible version handling <code>0.1.0</code> BSD 2-Clause or Apache-2.0 watchdog Filesystem events monitoring <code>&gt;=2.0</code> <code>6.0.0</code> Apache-2.0 wcmatch Wildcard/glob file name matcher. <code>10.1</code> MIT zipp Backport of pathlib-compatible object wrapper for zip files <code>&gt;=3.20</code> <code>3.23.0</code> MIT"},{"location":"licenses/","title":"Licenses","text":""},{"location":"licenses/#licenses","title":"Licenses","text":""},{"location":"licenses/#gnu-gpl-v30","title":"GNU GPL v3.0","text":"<p>The <code>gemseo-mma</code> source code is distributed under the GNU GPL v3.0 license. <pre><code>Copyright 2021 IRT Saint Exup\u00e9ry, https://www.irt-saintexupery.com\n\nThis program is free software; you can redistribute it and/or\nmodify it under the terms of the GNU General Public\nLicense version 3 as published by the Free Software Foundation.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\nGeneral Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software Foundation,\nInc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n</code></pre></p>"},{"location":"licenses/#bsd-0-clause","title":"BSD 0-Clause","text":"<p>The <code>gemseo-mma</code> examples are distributed under the BSD 0-Clause <pre><code>Copyright 2021 IRT Saint Exup\u00e9ry, https://www.irt-saintexupery.com\n\nThis work is licensed under a BSD 0-Clause License.\n\nPermission to use, copy, modify, and/or distribute this software\nfor any purpose with or without fee is hereby granted.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL\nWARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL\nTHE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\nOR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING\nFROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT,\nNEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION\nWITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n</code></pre></p>"},{"location":"licenses/#cc-by-sa-40","title":"CC BY-SA 4.0","text":"<p>The <code>gemseo-mma</code> documentation is distributed under the CC BY-SA 4.0 license. <pre><code>Copyright 2021 IRT Saint Exup\u00e9ry, https://www.irt-saintexupery.com\n\nThis work is licensed under the Creative Commons Attribution-ShareAlike 4.0\nInternational License. To view a copy of this license, visit\nhttp://creativecommons.org/licenses/by-sa/4.0/ or send a letter to Creative\nCommons, PO Box 1866, Mountain View, CA 94042, USA.\n</code></pre></p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>gemseo_mma<ul> <li>opt<ul> <li>core<ul> <li>mma</li> <li>mma_optimizer</li> </ul> </li> <li>mma</li> <li>mma_settings</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/gemseo_mma/","title":"API documentation","text":""},{"location":"reference/gemseo_mma/#gemseo_mma","title":"gemseo_mma","text":"<p>Svanberg MMA optimization solver wrapprer for GEMSEO.</p>"},{"location":"reference/gemseo_mma/opt/","title":"Opt","text":""},{"location":"reference/gemseo_mma/opt/#gemseo_mma.opt","title":"opt","text":"<p>Options for Bi-Level Outer Approximation.</p>"},{"location":"reference/gemseo_mma/opt/mma/","title":"Mma","text":""},{"location":"reference/gemseo_mma/opt/mma/#gemseo_mma.opt.mma","title":"mma","text":"<p>MMA optimizer library.</p>"},{"location":"reference/gemseo_mma/opt/mma/#gemseo_mma.opt.mma-classes","title":"Classes","text":""},{"location":"reference/gemseo_mma/opt/mma/#gemseo_mma.opt.mma.MMASvanberg","title":"MMASvanberg","text":"<p>               Bases: <code>BaseOptimizationLibrary[MMASvanberg_Settings]</code></p> <p>Svanberg Method of Moving Asymptotes optimization library.</p> Notes <p>The missing current values of the :class:<code>.DesignSpace</code> attached to the :class:<code>.OptimizationProblem</code> are automatically initialized with the method :meth:<code>.DesignSpace.initialize_missing_current_values</code>.</p>"},{"location":"reference/gemseo_mma/opt/mma_settings/","title":"Mma settings","text":""},{"location":"reference/gemseo_mma/opt/mma_settings/#gemseo_mma.opt.mma_settings","title":"mma_settings","text":"<p>Settings for the MMASvanberg algorithm.</p>"},{"location":"reference/gemseo_mma/opt/mma_settings/#gemseo_mma.opt.mma_settings-classes","title":"Classes","text":""},{"location":"reference/gemseo_mma/opt/mma_settings/#gemseo_mma.opt.mma_settings.MMASvanberg_Settings","title":"MMASvanberg_Settings","text":"<p>               Bases: <code>BaseOptimizerSettings</code>, <code>BaseGradientBasedAlgorithmSettings</code></p> <p>The settings for the MMA Svanberg algorithm.</p>"},{"location":"reference/gemseo_mma/opt/core/","title":"Core","text":""},{"location":"reference/gemseo_mma/opt/core/#gemseo_mma.opt.core","title":"core","text":"<p>Optimization algorithms package.</p>"},{"location":"reference/gemseo_mma/opt/core/mma/","title":"Mma","text":""},{"location":"reference/gemseo_mma/opt/core/mma/#gemseo_mma.opt.core.mma","title":"mma","text":"<p>GCMMA-MMA-Python. This file is part of GCMMA-MMA-Python.</p> <p>GCMMA-MMA-Python is licensed under the terms of GNU General Public License as published by the Free Software Foundation. For more information and the LICENSE file, see here. The original work is written by Krister Svanberg in MATLAB. This is the python version of the code written Arjen Deetman. version 09-11-2019.</p> <p>MMA optimizer.</p> <p>Original work written by Krister Svanberg in Matlab. This is the python version of the code written by Arjen Deetman.</p>"},{"location":"reference/gemseo_mma/opt/core/mma/#gemseo_mma.opt.core.mma-functions","title":"Functions","text":""},{"location":"reference/gemseo_mma/opt/core/mma/#gemseo_mma.opt.core.mma.compute_kkt_residual_on_local_approximation","title":"compute_kkt_residual_on_local_approximation","text":"<pre><code>compute_kkt_residual_on_local_approximation(\n    m: int,\n    n: int,\n    x: ndarray,\n    y: ndarray,\n    z: ndarray,\n    lam: ndarray,\n    xsi: ndarray,\n    eta: ndarray,\n    mu: ndarray,\n    zet: ndarray,\n    s: ndarray,\n    xmin: ndarray,\n    xmax: ndarray,\n    df0dx: ndarray,\n    fval: ndarray,\n    dfdx: ndarray,\n    a0: float,\n    a: ndarray,\n    c: ndarray,\n    d: ndarray,\n) -&gt; tuple[ndarray, ndarray, ndarray]\n</code></pre> <p>KKT residual computation.</p> <p>The left hand sides of the KKT conditions for the following nonlinear programming problem are calculated.</p> <p>Minimize f_0(x) + a_0z + sum(c_iy_i + 0.5d_i(y_i)^2) subject to  f_i(x) - a_i*z - y_i &lt;= 0,   i = 1,...,m             xmax_j &lt;= x_j &lt;= xmin_j,     j = 1,...,n             z &gt;= 0,   y_i &gt;= 0,          i = 1,...,m</p> <p>Parameters:</p> <ul> <li> <code>m</code>               (<code>int</code>)           \u2013            <p>The number of general constraints.</p> </li> <li> <code>n</code>               (<code>int</code>)           \u2013            <p>The number of variables x_j.</p> </li> <li> <code>x</code>               (<code>ndarray</code>)           \u2013            <p>The current values of the n variables x_j.</p> </li> <li> <code>y</code>               (<code>ndarray</code>)           \u2013            <p>The current values of the m variables y_i.</p> </li> <li> <code>z</code>               (<code>ndarray</code>)           \u2013            <p>The current value of the single variable z.</p> </li> <li> <code>lam</code>               (<code>ndarray</code>)           \u2013            <p>The Lagrange multipliers for the m general constraints.</p> </li> <li> <code>xsi</code>               (<code>ndarray</code>)           \u2013            <p>The Lagrange multipliers for the n constraints xmin_j - x_j &lt;= 0.</p> </li> <li> <code>eta</code>               (<code>ndarray</code>)           \u2013            <p>The Lagrange multipliers for the n constraints x_j - xmax_j &lt;= 0.</p> </li> <li> <code>mu</code>               (<code>ndarray</code>)           \u2013            <p>The Lagrange multipliers for the m constraints -y_i &lt;= 0.</p> </li> <li> <code>zet</code>               (<code>ndarray</code>)           \u2013            <p>The Lagrange multiplier for the single constraint -z &lt;= 0.</p> </li> <li> <code>s</code>               (<code>ndarray</code>)           \u2013            <p>The Slack variables for the m general constraints.</p> </li> <li> <code>xmin</code>               (<code>ndarray</code>)           \u2013            <p>The Lower bounds for the variables x_j.</p> </li> <li> <code>xmax</code>               (<code>ndarray</code>)           \u2013            <p>The Upper bounds for the variables x_j.</p> </li> <li> <code>df0dx</code>               (<code>ndarray</code>)           \u2013            <p>The vector with the derivatives of the objective function f_0 with respect to the variables x_j, calculated at x.</p> </li> <li> <code>fval</code>               (<code>ndarray</code>)           \u2013            <p>The vector with the values of the constraint functions f_i, calculated</p> </li> <li> <code>dfdx</code>               (<code>ndarray</code>)           \u2013            <p>The (m x n)-matrix with the derivatives of the constraint functions f_i with respect to the variables x_j, calculated at x. dfdx(i,j) = the derivative of f_i with respect to x_j.</p> </li> <li> <code>a0</code>               (<code>float</code>)           \u2013            <p>The constants a_0 in the term a_0*z.</p> </li> <li> <code>a</code>               (<code>ndarray</code>)           \u2013            <p>The vector with the constants a_i in the terms a_i*z.</p> </li> <li> <code>c</code>               (<code>ndarray</code>)           \u2013            <p>The vector with the constants c_i in the terms c_i*y_i.</p> </li> <li> <code>d</code>               (<code>ndarray</code>)           \u2013            <p>The vector with the constants d_i in the terms 0.5d_i(y_i)^2.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[ndarray, ndarray, ndarray]</code>           \u2013            <p>The vector residual, its norm and its maximum.</p> </li> </ul> Source code in <code>src/gemseo_mma/opt/core/mma.py</code> <pre><code>def compute_kkt_residual_on_local_approximation(\n    m: int,\n    n: int,\n    x: ndarray,\n    y: ndarray,\n    z: ndarray,\n    lam: ndarray,\n    xsi: ndarray,\n    eta: ndarray,\n    mu: ndarray,\n    zet: ndarray,\n    s: ndarray,\n    xmin: ndarray,\n    xmax: ndarray,\n    df0dx: ndarray,\n    fval: ndarray,\n    dfdx: ndarray,\n    a0: float,\n    a: ndarray,\n    c: ndarray,\n    d: ndarray,\n) -&gt; tuple[ndarray, ndarray, ndarray]:\n    \"\"\"KKT residual computation.\n\n    The left hand sides of the KKT conditions for the following nonlinear programming\n    problem are calculated.\n\n    Minimize f_0(x) + a_0*z + sum(c_i*y_i + 0.5*d_i*(y_i)^2)\n    subject to  f_i(x) - a_i*z - y_i &lt;= 0,   i = 1,...,m\n                xmax_j &lt;= x_j &lt;= xmin_j,     j = 1,...,n\n                z &gt;= 0,   y_i &gt;= 0,          i = 1,...,m\n\n    Args:\n        m: The number of general constraints.\n        n: The number of variables x_j.\n        x: The current values of the n variables x_j.\n        y: The current values of the m variables y_i.\n        z: The current value of the single variable z.\n        lam: The Lagrange multipliers for the m general constraints.\n        xsi: The Lagrange multipliers for the n constraints xmin_j - x_j &lt;= 0.\n        eta: The Lagrange multipliers for the n constraints x_j - xmax_j &lt;= 0.\n        mu:  The Lagrange multipliers for the m constraints -y_i &lt;= 0.\n        zet: The Lagrange multiplier for the single constraint -z &lt;= 0.\n        s: The Slack variables for the m general constraints.\n        xmin: The Lower bounds for the variables x_j.\n        xmax: The Upper bounds for the variables x_j.\n        df0dx: The vector with the derivatives of the objective function f_0 with\n            respect to the variables x_j, calculated at x.\n        fval: The vector with the values of the constraint functions f_i, calculated\n        at x.\n        dfdx: The (m x n)-matrix with the derivatives of the constraint functions f_i\n            with respect to the variables x_j, calculated at x.\n            dfdx(i,j) = the derivative of f_i with respect to x_j.\n        a0: The constants a_0 in the term a_0*z.\n        a: The vector with the constants a_i in the terms a_i*z.\n        c: The vector with the constants c_i in the terms c_i*y_i.\n        d: The vector with the constants d_i in the terms 0.5*d_i*(y_i)^2.\n\n    Returns:\n        The vector residual, its norm and its maximum.\n    \"\"\"\n    rex = df0dx + np.dot(dfdx.T, lam) - xsi + eta\n    rey = c + d * y - mu - lam\n    rez = a0 - zet - np.dot(a.T, lam)\n    relam = fval - a * z - y + s\n    rexsi = xsi * (x - xmin)\n    reeta = eta * (xmax - x)\n    remu = mu * y\n    rezet = zet * z\n    res = lam * s\n    residu1 = np.concatenate((rex, rey, rez), axis=0)\n    residu2 = np.concatenate((relam, rexsi, reeta, remu, rezet, res), axis=0)\n    residu = np.concatenate((residu1, residu2), axis=0)\n    residunorm = np.sqrt((np.dot(residu.T, residu)).item())\n    residumax = np.max(np.abs(residu))\n    return residu, residunorm, residumax\n</code></pre>"},{"location":"reference/gemseo_mma/opt/core/mma/#gemseo_mma.opt.core.mma.solve_mma_local_approximation_problem","title":"solve_mma_local_approximation_problem","text":"<pre><code>solve_mma_local_approximation_problem(\n    m: int,\n    n: int,\n    n_iterations: int,\n    xval: ndarray,\n    xmin: ndarray,\n    xmax: ndarray,\n    xold1: ndarray,\n    xold2: ndarray,\n    f0val: ndarray,\n    df0dx: ndarray,\n    fval: ndarray,\n    dfdx: ndarray,\n    low: ndarray,\n    upp: ndarray,\n    a0: float,\n    a: ndarray,\n    c: ndarray,\n    d: ndarray,\n    move: float,\n    external_move_limit: float = 10.0,\n    internal_limit: float = 0.01,\n    asyinit: float = 0.5,\n    asyincr: float = 1.2,\n    asydecr: float = 0.7,\n) -&gt; tuple[\n    ndarray,\n    ndarray,\n    ndarray,\n    ndarray,\n    ndarray,\n    ndarray,\n    ndarray,\n    ndarray,\n    ndarray,\n    ndarray,\n    ndarray,\n]\n</code></pre> <p>MMA sub function.</p> <p>This function mmasub performs one MMA-iteration, aimed at solving the nonlinear programming problem:</p> <p>Minimize    f_0(x) + a_0z + sum( c_iy_i + 0.5d_i(y_i)^2 ) subject to  f_i(x) - a_i*z - y_i &lt;= 0,  i = 1,...,m             xmin_j &lt;= x_j &lt;= xmax_j,    j = 1,...,n             z &gt;= 0,   y_i &gt;= 0,         i = 1,...,m</p> <p>Parameters:</p> <ul> <li> <code>m</code>               (<code>int</code>)           \u2013            <p>The number of general constraints.</p> </li> <li> <code>n</code>               (<code>int</code>)           \u2013            <p>The number of variables x_j.</p> </li> <li> <code>n_iterations</code>               (<code>int</code>)           \u2013            <p>The current iteration number (=1 the first time mmasub is called).</p> </li> <li> <code>xval</code>               (<code>ndarray</code>)           \u2013            <p>The column vector with the current values of the variables x_j.</p> </li> <li> <code>xmin</code>               (<code>ndarray</code>)           \u2013            <p>The column vector with the lower bounds for the variables x_j.</p> </li> <li> <code>xmax</code>               (<code>ndarray</code>)           \u2013            <p>The column vector with the upper bounds for the variables x_j.</p> </li> <li> <code>xold1</code>               (<code>ndarray</code>)           \u2013            <p>The value of xval, one iteration ago (provided that n_iterations&gt;1).</p> </li> <li> <code>xold2</code>               (<code>ndarray</code>)           \u2013            <p>The value of xval, two iterations ago (provided that n_iterations&gt;2).</p> </li> <li> <code>f0val</code>               (<code>ndarray</code>)           \u2013            <p>The value of the objective function f_0 at xval.</p> </li> <li> <code>df0dx</code>               (<code>ndarray</code>)           \u2013            <p>The column vector with the derivatives of the objective function f_0 with respect to the variables x_j, calculated at xval.</p> </li> <li> <code>fval</code>               (<code>ndarray</code>)           \u2013            <p>The column vector with the values of the constraint functions f_i, calculated at xval.</p> </li> <li> <code>dfdx</code>               (<code>ndarray</code>)           \u2013            <p>The (m x n)-matrix with the derivatives of the constraint functions f_i with respect to the variables x_j, calculated at xval.</p> </li> <li> <code>low</code>               (<code>ndarray</code>)           \u2013            <p>The column vector with the lower asymptotes from the previous iteration (provided that n_iterations&gt;1).</p> </li> <li> <code>upp</code>               (<code>ndarray</code>)           \u2013            <p>The column vector with the upper asymptotes from the previous iteration (provided that n_iterations&gt;1).</p> </li> <li> <code>a0</code>               (<code>float</code>)           \u2013            <p>The constants a_0 in the term a_0*z.</p> </li> <li> <code>a</code>               (<code>ndarray</code>)           \u2013            <p>The column vector with the constants a_i in the terms a_i*z.</p> </li> <li> <code>c</code>               (<code>ndarray</code>)           \u2013            <p>The column vector with the constants c_i in the terms c_i*y_i.</p> </li> <li> <code>d</code>               (<code>ndarray</code>)           \u2013            <p>The column vector with the constants d_i in the terms 0.5d_i(y_i)^2.</p> </li> <li> <code>move</code>               (<code>float</code>)           \u2013            <p>The maximum optimization step.</p> </li> <li> <code>external_move_limit</code>               (<code>float</code>, default:                   <code>10.0</code> )           \u2013            <p>The maximum distance of the asymptotes from the current design variable value.</p> </li> <li> <code>internal_limit</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>The minimum distance of the asymptotes from the current design variable value.</p> </li> <li> <code>asyinit</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>The initial asymptotes distance from the current design variable value.</p> </li> <li> <code>asyincr</code>               (<code>float</code>, default:                   <code>1.2</code> )           \u2013            <p>The incremental factor for successful iterations.</p> </li> <li> <code>asydecr</code>               (<code>float</code>, default:                   <code>0.7</code> )           \u2013            <p>The decremental factor for unsuccessful iterations.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[ndarray, ndarray, ndarray, ndarray, ndarray, ndarray, ndarray, ndarray, ndarray, ndarray, ndarray]</code>           \u2013            <p>The Column vector with the optimal values of the variables x_j in the current MMA subproblem.</p> <p>The Column vector with the optimal values of the variables y_i in the current MMA subproblem.</p> <p>The Scalar with the optimal value of the variable z in the current MMA subproblem.</p> <p>The Lagrange multipliers for the m general MMA constraints.</p> <p>The Lagrange multipliers for the n constraints alfa_j - x_j &lt;= 0.</p> <p>The Lagrange multipliers for the n constraints x_j - beta_j &lt;= 0.</p> <p>The Lagrange multipliers for the m constraints -y_i &lt;= 0.</p> <p>The Lagrange multiplier for the single constraint -z &lt;= 0.</p> <p>The Slack variables for the m general MMA constraints.</p> <p>The Column vector with the lower asymptotes, calculated and used in the current MMA subproblem.</p> <p>The Column vector with the upper asymptotes, calculated and used in the current MMA subproblem.</p> </li> </ul> Source code in <code>src/gemseo_mma/opt/core/mma.py</code> <pre><code>def solve_mma_local_approximation_problem(\n    m: int,\n    n: int,\n    n_iterations: int,\n    xval: ndarray,\n    xmin: ndarray,\n    xmax: ndarray,\n    xold1: ndarray,\n    xold2: ndarray,\n    f0val: ndarray,\n    df0dx: ndarray,\n    fval: ndarray,\n    dfdx: ndarray,\n    low: ndarray,\n    upp: ndarray,\n    a0: float,\n    a: ndarray,\n    c: ndarray,\n    d: ndarray,\n    move: float,\n    external_move_limit: float = 10.0,\n    internal_limit: float = 0.01,\n    asyinit: float = 0.5,\n    asyincr: float = 1.2,\n    asydecr: float = 0.7,\n) -&gt; tuple[\n    ndarray,\n    ndarray,\n    ndarray,\n    ndarray,\n    ndarray,\n    ndarray,\n    ndarray,\n    ndarray,\n    ndarray,\n    ndarray,\n    ndarray,\n]:\n    \"\"\"MMA sub function.\n\n    This function mmasub performs one MMA-iteration, aimed at solving the nonlinear\n    programming problem:\n\n    Minimize    f_0(x) + a_0*z + sum( c_i*y_i + 0.5*d_i*(y_i)^2 )\n    subject to  f_i(x) - a_i*z - y_i &lt;= 0,  i = 1,...,m\n                xmin_j &lt;= x_j &lt;= xmax_j,    j = 1,...,n\n                z &gt;= 0,   y_i &gt;= 0,         i = 1,...,m\n\n    Args:\n        m: The number of general constraints.\n        n: The number of variables x_j.\n        n_iterations: The current iteration number\n            (=1 the first time mmasub is called).\n        xval: The column vector with the current values of the variables x_j.\n        xmin: The column vector with the lower bounds for the variables x_j.\n        xmax: The column vector with the upper bounds for the variables x_j.\n        xold1: The value of xval, one iteration ago (provided that n_iterations&gt;1).\n        xold2: The value of xval, two iterations ago (provided that n_iterations&gt;2).\n        f0val: The value of the objective function f_0 at xval.\n        df0dx: The column vector with the derivatives of the objective function\n            f_0 with respect to the variables x_j, calculated at xval.\n        fval: The column vector with the values of the constraint functions f_i,\n            calculated at xval.\n        dfdx: The (m x n)-matrix with the derivatives of the constraint functions\n            f_i with respect to the variables x_j, calculated at xval.\n        low: The column vector with the lower asymptotes from the previous\n            iteration (provided that n_iterations&gt;1).\n        upp: The column vector with the upper asymptotes from the previous\n            iteration (provided that n_iterations&gt;1).\n        a0: The constants a_0 in the term a_0*z.\n        a: The column vector with the constants a_i in the terms a_i*z.\n        c: The column vector with the constants c_i in the terms c_i*y_i.\n        d: The column vector with the constants d_i in the terms 0.5*d_i*(y_i)^2.\n        move: The maximum optimization step.\n        external_move_limit: The maximum distance of the asymptotes from the current\n            design variable value.\n        internal_limit: The minimum distance of the asymptotes from the current design\n            variable value.\n        asyinit: The initial asymptotes distance from the current design variable value.\n        asyincr: The incremental factor for successful iterations.\n        asydecr: The decremental factor for unsuccessful iterations.\n\n    Returns:\n        The Column vector with the optimal values of the variables x_j\n        in the current MMA subproblem.\n\n        The Column vector with the optimal values of the variables y_i\n        in the current MMA subproblem.\n\n        The Scalar with the optimal value of the variable z\n        in the current MMA subproblem.\n\n        The Lagrange multipliers for the m general MMA constraints.\n\n        The Lagrange multipliers for the n constraints alfa_j - x_j &lt;= 0.\n\n        The Lagrange multipliers for the n constraints x_j - beta_j &lt;= 0.\n\n        The Lagrange multipliers for the m constraints -y_i &lt;= 0.\n\n        The Lagrange multiplier for the single constraint -z &lt;= 0.\n\n        The Slack variables for the m general MMA constraints.\n\n        The Column vector with the lower asymptotes, calculated and used\n        in the current MMA subproblem.\n\n        The Column vector with the upper asymptotes, calculated and used\n        in the current MMA subproblem.\n    \"\"\"\n    epsimin = 0.0000001\n    raa0 = 0.00001\n    albefa = 0.1\n    eeen = np.ones((n, 1))\n    eeem = np.ones((m, 1))\n    zeron = np.zeros((n, 1))\n    # Calculation of the asymptotes low and upp\n    if n_iterations &lt;= 2:\n        low = xval - asyinit * (xmax - xmin)\n        upp = xval + asyinit * (xmax - xmin)\n    else:\n        zzz = (xval - xold1) * (xold1 - xold2)\n        factor = eeen.copy()\n        factor[np.where(zzz &gt; 0)] = asyincr\n        factor[np.where(zzz &lt; 0)] = asydecr\n        low = xval - factor * (xold1 - low)\n        upp = xval + factor * (upp - xold1)\n        lowmin = xval - external_move_limit * (xmax - xmin)\n        lowmax = xval - internal_limit * (xmax - xmin)\n        uppmin = xval + internal_limit * (xmax - xmin)\n        uppmax = xval + external_move_limit * (xmax - xmin)\n        low = np.maximum(low, lowmin)\n        low = np.minimum(low, lowmax)\n        upp = np.minimum(upp, uppmax)\n        upp = np.maximum(upp, uppmin)\n    # Calculation of the bounds alfa and beta\n    zzz1 = low + albefa * (xval - low)\n    zzz2 = xval - move * (xmax - xmin)\n    zzz = np.maximum(zzz1, zzz2)\n    alfa = np.maximum(zzz, xmin)\n    zzz1 = upp - albefa * (upp - xval)\n    zzz2 = xval + move * (xmax - xmin)\n    zzz = np.minimum(zzz1, zzz2)\n    beta = np.minimum(zzz, xmax)\n    # Calculations of p0, q0, pp, qq and b\n    xmami = xmax - xmin\n    xmamieps = 0.00001 * eeen\n    xmami = np.maximum(xmami, xmamieps)\n    xmamiinv = eeen / xmami\n    ux1 = upp - xval\n    ux2 = ux1 * ux1\n    xl1 = xval - low\n    xl2 = xl1 * xl1\n    uxinv = eeen / ux1\n    xlinv = eeen / xl1\n    p0 = zeron.copy()\n    q0 = zeron.copy()\n    p0 = np.maximum(df0dx, 0)\n    q0 = np.maximum(-df0dx, 0)\n    pq0 = 0.001 * (p0 + q0) + raa0 * xmamiinv\n    p0 = p0 + pq0\n    q0 = q0 + pq0\n    p0 = p0 * ux2\n    q0 = q0 * xl2\n    pp = np.zeros((m, n))\n    qq = np.zeros((m, n))\n    pp = np.maximum(dfdx, 0)\n    qq = np.maximum(-dfdx, 0)\n    ppqq = 0.001 * (pp + qq) + raa0 * np.dot(eeem, xmamiinv.T)\n    pp = pp + ppqq\n    qq = qq + ppqq\n    pp = (diags(ux2.flatten(), 0).dot(pp.T)).T\n    qq = (diags(xl2.flatten(), 0).dot(qq.T)).T\n    b = np.dot(pp, uxinv) + np.dot(qq, xlinv) - fval\n    xmma, ymma, zmma, lam, xsi, eta, mu, zet, s = __subsolv(\n        m, n, epsimin, low, upp, alfa, beta, p0, q0, pp, qq, a0, a, b, c, d\n    )\n    # Return values\n    return xmma, ymma, zmma, lam, xsi, eta, mu, zet, s, low, upp\n</code></pre>"},{"location":"reference/gemseo_mma/opt/core/mma_optimizer/","title":"Mma optimizer","text":""},{"location":"reference/gemseo_mma/opt/core/mma_optimizer/#gemseo_mma.opt.core.mma_optimizer","title":"mma_optimizer","text":"<p>MMA optimization solver.</p>"},{"location":"reference/gemseo_mma/opt/core/mma_optimizer/#gemseo_mma.opt.core.mma_optimizer-classes","title":"Classes","text":""},{"location":"reference/gemseo_mma/opt/core/mma_optimizer/#gemseo_mma.opt.core.mma_optimizer.MMAOptimizer","title":"MMAOptimizer","text":"<pre><code>MMAOptimizer(problem: OptimizationProblem)\n</code></pre> <p>Method of Moving Asymptotes optimizer class.</p> <p>This class run an optimization algorithm to solve Non-linear Optimization problems with constraints. The objective function and the constraints and their gradients are needed for the optimization algorithm. The original implementation the next iteration candidate is computed using mmasub function adapted from this. The external and internal move limit can be tuned to control minimum and maximum local approximation convexity. The max_optimization_step parameter can be used to control the optimization step. To avoid solver divergence in the case of highly non-linear problems one should use smaller values of the <code>max_optimization_step</code>, <code>max_asymptote_distance</code> and <code>min_asymptote_distance</code>.</p> <p>Constructor.</p> Source code in <code>src/gemseo_mma/opt/core/mma_optimizer.py</code> <pre><code>def __init__(self, problem: OptimizationProblem) -&gt; None:\n    \"\"\"Constructor.\"\"\"\n    self.__problem = problem\n    self.__message = self.__EMPTY_STRING\n    self.__normalize_design_space = self.__DEFAULT_NORMALIZE_DESIGN_SPACE\n    self.__max_iter = self.__DEFAULT_MAXITER\n    self.__tol = self.__DEFAULT_KKT_TOL\n    self.__xtol_abs = self.__DEFAULT_TOLERANCE\n    self.__xtol_rel = self.__DEFAULT_TOLERANCE\n    self.__ftol_rel = self.__DEFAULT_TOLERANCE\n    self.__ftol_abs = self.__DEFAULT_TOLERANCE\n    self.__ineq_tolerance = self.__DEFAULT_TOLERANCE\n    self.__max_asymptote_distance = self.__DEFAULT_MAX_DISTANCE\n    self.__min_asymptote_distance = self.__DEFAULT_MIN_DISTANCE\n    self.__max_optimization_step = self.__DEFAULT_MAX_OPTIM_STEP\n    self.__initial_asymptotes_distance = self.__DEFAULT_ASYINIT\n    self.__asymptotes_distance_amplification_coefficient = self.__DEFAULT_ASYINCR\n    self.__asymptotes_distance_reduction_coefficient = self.__DEFAULT_ASYDECR\n</code></pre>"},{"location":"reference/gemseo_mma/opt/core/mma_optimizer/#gemseo_mma.opt.core.mma_optimizer.MMAOptimizer-functions","title":"Functions","text":""},{"location":"reference/gemseo_mma/opt/core/mma_optimizer/#gemseo_mma.opt.core.mma_optimizer.MMAOptimizer.iterate","title":"iterate","text":"<pre><code>iterate(x0: ndarray) -&gt; tuple[ndarray, ndarray]\n</code></pre> <p>Iterate until convergence from the starting guess.</p> <p>Parameters:</p> <ul> <li> <code>x0</code>               (<code>ndarray</code>)           \u2013            <p>The starting guess design point.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[ndarray, ndarray]</code>           \u2013            <p>The optimum design point and objective value.</p> </li> </ul> Source code in <code>src/gemseo_mma/opt/core/mma_optimizer.py</code> <pre><code>def iterate(self, x0: ndarray) -&gt; tuple[ndarray, ndarray]:\n    \"\"\"Iterate until convergence from the starting guess.\n\n    Args:\n        x0: The starting guess design point.\n\n    Returns:\n        The optimum design point and objective value.\n    \"\"\"\n    n = len(x0)\n    eeen = np.ones((n, 1))\n    xval = np.reshape(x0, eeen.shape)\n    xold1 = xval.copy()\n    xold2 = xval.copy()\n    if not self.__normalize_design_space:\n        xmin = np.reshape(\n            self.__problem.design_space.get_lower_bounds(), eeen.shape\n        )\n        xmax = np.reshape(\n            self.__problem.design_space.get_upper_bounds(), eeen.shape\n        )\n    else:\n        xmin = 0 * eeen\n        xmax = eeen\n    low = xmin.copy()\n    upp = xmax.copy()\n\n    a0 = 1\n\n    outeriter = 0\n    maxoutit = self.__max_iter\n    kkttol = self.__tol\n    (\n        f0val,\n        df0dx,\n        fval,\n        dfdx,\n    ) = self.__get_objective_and_constraints_with_gradients(xval.flatten())\n    m = len(fval)\n    eeem = np.ones((m, 1))\n    zerom = np.zeros((m, 1))\n    c = 1000 * eeem\n    d = eeem.copy()\n    a = zerom.copy()\n    # The iterations starts\n    kktnorm = kkttol + 10\n    f_ref = f0val\n    x_ref = np.linalg.norm(xval)\n    change_fc = 10\n    change_f = 10\n    change_x = 10\n    change_relative_f = 10\n    change_relative_x = 10\n    outit = 0\n    while (\n        (\n            (kktnorm &gt; kkttol)\n            and (change_x &gt; self.__xtol_abs)\n            and (change_relative_x &gt; self.__xtol_rel)\n            and (change_relative_f &gt; self.__ftol_rel)\n            and (change_f &gt; self.__ftol_abs)\n        )\n        or (any(fval &gt; self.__ineq_tolerance) and change_fc &gt; self.__ftol_abs)\n    ) and (outit &lt; maxoutit):\n        outit += 1\n        outeriter += 1\n\n        (\n            xmma,\n            ymma,\n            zmma,\n            lam,\n            xsi,\n            eta,\n            mu,\n            zet,\n            s,\n            low,\n            upp,\n        ) = solve_mma_local_approximation_problem(\n            m,\n            n,\n            outeriter,\n            xval,\n            xmin,\n            xmax,\n            xold1,\n            xold2,\n            f0val,\n            df0dx,\n            fval,\n            dfdx,\n            low,\n            upp,\n            a0,\n            a,\n            c,\n            d,\n            self.__max_optimization_step,\n            self.__max_asymptote_distance,\n            self.__min_asymptote_distance,\n            self.__initial_asymptotes_distance,\n            self.__asymptotes_distance_amplification_coefficient,\n            self.__asymptotes_distance_reduction_coefficient,\n        )\n        (\n            f0valnew,\n            df0dxnew,\n            fvalnew,\n            dfdxnew,\n        ) = self.__get_objective_and_constraints_with_gradients(xmma.flatten())\n        change_x = np.linalg.norm(xval - xmma)\n        change_f = np.abs(f0valnew - f0val)\n        change_fc = np.abs(fvalnew.max() - fval.max())\n        change_relative_x = change_x / x_ref\n        change_relative_f = change_f / f_ref\n        # Some vectors are updated:\n        xold2 = xold1.copy()\n        xold1 = xval.copy()\n        xval = xmma.copy()\n        # Re-calculate function values and gradients of the objective and\n        # constraints functions\n        f0val, df0dx, fval, dfdx = f0valnew, df0dxnew, fvalnew, dfdxnew\n        # The residual vector of the KKT conditions is calculated\n        _, kktnorm, _ = compute_kkt_residual_on_local_approximation(\n            m,\n            n,\n            xmma,\n            ymma,\n            zmma,\n            lam,\n            xsi,\n            eta,\n            mu,\n            zet,\n            s,\n            xmin,\n            xmax,\n            df0dx,\n            fval,\n            dfdx,\n            a0,\n            a,\n            c,\n            d,\n        )\n\n    if self.__normalize_design_space:\n        xopt = self.__problem.design_space.unnormalize_vect(xval.flatten())\n    else:\n        xopt = xval.flatten()\n\n    LOGGER.info(\"END OF MMA ALGORITHM\")\n    if kktnorm &lt;= kkttol:\n        self.__message = \"KKT norm criteria met\"\n    else:\n        self.__message = \"change criteria met\"\n    return xopt, f0val\n</code></pre>"},{"location":"reference/gemseo_mma/opt/core/mma_optimizer/#gemseo_mma.opt.core.mma_optimizer.MMAOptimizer.optimize","title":"optimize","text":"<pre><code>optimize(**options: bool | float) -&gt; tuple[str, int]\n</code></pre> <p>Optimize the problem.</p> <p>Parameters:</p> <ul> <li> <code>**options</code>               (<code>bool | float</code>, default:                   <code>{}</code> )           \u2013            <p>The optimization problem options.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[str, int]</code>           \u2013            <p>The optimization solver message and final status.</p> </li> </ul> Source code in <code>src/gemseo_mma/opt/core/mma_optimizer.py</code> <pre><code>def optimize(self, **options: bool | float) -&gt; tuple[str, int]:\n    \"\"\"Optimize the problem.\n\n    Args:\n        **options: The optimization problem options.\n\n    Returns:\n        The optimization solver message and final status.\n    \"\"\"\n    self.__normalize_design_space = options.get(\n        \"normalize_design_space\", self.__DEFAULT_NORMALIZE_DESIGN_SPACE\n    )\n    self.__max_iter = options.get(\"max_iter\", self.__DEFAULT_MAXITER)\n    self.__tol = options.get(\"tol\", self.__DEFAULT_TOLERANCE)\n    self.__xtol_abs = options.get(\"xtol_abs\", self.__DEFAULT_TOLERANCE)\n    self.__xtol_rel = options.get(\"xtol_rel\", self.__DEFAULT_TOLERANCE)\n    self.__ftol_rel = options.get(\"ftol_rel\", self.__DEFAULT_TOLERANCE)\n    self.__ftol_abs = options.get(\"ftol_abs\", self.__DEFAULT_TOLERANCE)\n    self.__max_asymptote_distance = options.get(\n        \"max_asymptote_distance\", self.__DEFAULT_MAX_DISTANCE\n    )\n    self.__min_asymptote_distance = options.get(\n        \"min_asymptote_distance\", self.__DEFAULT_MIN_DISTANCE\n    )\n    self.__max_optimization_step = options.get(\n        \"max_optimization_step\", self.__DEFAULT_MAX_OPTIM_STEP\n    )\n    self.__initial_asymptotes_distance = options.get(\n        \"initial_asymptotes_distance\", self.__DEFAULT_ASYINIT\n    )\n    self.__asymptotes_distance_amplification_coefficient = options.get(\n        \"asymptotes_distance_amplification_coefficient\", self.__DEFAULT_ASYINCR\n    )\n    self.__asymptotes_distance_reduction_coefficient = options.get(\n        \"asymptotes_distance_reduction_coefficient\", self.__DEFAULT_ASYDECR\n    )\n    self.__ineq_tolerance = options.get(\"ineq_tolerance\", self.__DEFAULT_TOLERANCE)\n\n    # initialize database\n    if not self.__normalize_design_space:\n        x0 = self.__problem.design_space.get_current_value()\n    else:\n        x0 = self.__problem.design_space.normalize_vect(\n            self.__problem.design_space.get_current_value()\n        )\n\n    # launch optim\n    xopt = self.iterate(x0)[0]\n    self.__problem.design_space.set_current_value(xopt)\n\n    return self.__message, 0\n</code></pre>"},{"location":"reference/gemseo_mma/opt/core/mma_optimizer/#gemseo_mma.opt.core.mma_optimizer-functions","title":"Functions","text":""},{"location":"user_guide/","title":"User guide","text":""},{"location":"user_guide/#user-guide","title":"User guide","text":"<p>Like any other gemseo wrapped solver, MMA solver can be called setting the algo option to <code>\"MMA\"</code>. This algorithm can be used for single objective continuous optimization problem with non-linear inequality constraints.</p> <p>Advanced options:</p> <ul> <li><code>tol</code>: The KKT residual norm tolerance. This is not the one     implemented in GEMSEO as it uses the local functions to be computed.</li> <li><code>max_optimization_step</code>: Also known as <code>move</code> parameter control the     maximum distance of the next iteration design point from the current     one. Reducing this parameter avoid divergence for highly non-linear     problems.</li> <li><code>min_asymptote_distance</code>: The minimum distance of the asymptotes from     the current design variable value.</li> <li><code>max_asymptote_distance</code>: The maximum distance of the asymptotes from     the current design variable value.</li> <li><code>initial_asymptotes_distance</code>: The initial asymptote distance from the     current design variable value.</li> <li><code>asymptotes_distance_amplification_coefficient</code> The incremental factor     of asymptote distance from the current design variable value for     successful iterations.</li> <li><code>asymptotes_distance_reduction_coefficient</code>: The decremental factor of     asymptote distance from the current design variable value for     successful iterations.</li> <li><code>conv_tol</code>: If provided control all other convergence tolerances.</li> </ul> <p>The shortest is the distance of the asymptotes, the highest is the convexity of the local approximation. It's another mechanism to control the optimization step. You can find this example.</p>"}]}